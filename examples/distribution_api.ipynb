{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array([[[0., 0., 0., 1.]]], dtype=float32)]\n",
      "[[0. 1.]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp \n",
    "\n",
    "from pymdp.jax import Distribution\n",
    "from pymdp.jax.agent import Agent\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "observations = [\"A\", \"B\", \"C\", \"D\"]\n",
    "states = [\"A\", \"B\", \"C\", \"D\"]\n",
    "controls = [\"up\", \"down\"]\n",
    "\n",
    "data = np.zeros((len(observations), len(states)))\n",
    "likelihood = Distribution(data, {\"observations\": observations}, {\"states\": states})\n",
    "\n",
    "likelihood[\"A\", \"A\"] = 1.0 \n",
    "likelihood[\"B\", \"B\"] = 1.0\n",
    "likelihood[\"C\", \"C\"] = 1.0\n",
    "likelihood[\"D\", \"D\"] = 1.0\n",
    "\n",
    "data = np.zeros((len(states), len(states), len(controls)))\n",
    "transition = Distribution(data, {\"states\": states}, {\"states\": states, \"controls\": controls})\n",
    "\n",
    "transition[\"B\", \"A\", \"up\"] = 1.0\n",
    "transition[\"C\", \"B\", \"up\"] = 1.0\n",
    "transition[\"D\", \"C\", \"up\"] = 1.0\n",
    "transition[\"D\", \"D\", \"up\"] = 1.0\n",
    "\n",
    "transition[\"A\", \"A\", \"down\"] = 1.0\n",
    "transition[\"A\", \"B\", \"down\"] = 1.0\n",
    "transition[\"B\", \"C\", \"down\"] = 1.0\n",
    "transition[\"C\", \"D\", \"down\"] = 1.0\n",
    "\n",
    "A = [jnp.broadcast_to(likelihood.data, (1,) + likelihood.data.shape)]\n",
    "B = [jnp.broadcast_to(transition.data, (1,) + transition.data.shape)]\n",
    "\n",
    "\n",
    "C = [jnp.zeros((1, 4))]\n",
    "C[0] = C[0].at[0, 0].set(1.0)\n",
    "D = jnp.ones((1, 4)) / 8.0\n",
    "E = jnp.ones((1, 2)) / 4.0\n",
    "\n",
    "policies = jnp.expand_dims(jnp.array([[0, 0, 0, 0], [1, 1, 1, 1]]), -1)\n",
    "\n",
    "\n",
    "agent = Agent(A, B, C, D, E, A, B, policies=policies)\n",
    "\n",
    "observation = [jnp.array([[3]])]\n",
    "action = jnp.array([[0]])\n",
    "\n",
    "qs = [jnp.zeros((1, 1, 4))]\n",
    "qs[0] = qs[0].at[0, 0, 3].set(1.0)\n",
    "\n",
    "prior, _ = agent.update_empirical_prior(action, qs)\n",
    "\n",
    "\n",
    "qs = agent.infer_states(observation, None, prior, None)\n",
    "print(qs)\n",
    "\n",
    "q_pi, G = agent.infer_policies(qs)\n",
    "print(q_pi)\n",
    "key = jax.random.PRNGKey(0)\n",
    "action = agent.sample_action(q_pi)\n",
    "print(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
