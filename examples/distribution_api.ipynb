{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Distributions API\n",
    "\n",
    "In this notebook we'll give some example uses of the named distribution api\n",
    "designed for easier querying and construction of complicated A and B tensors.\n",
    "\n",
    "The distribution objects allow for giving semantically sensible names to axes\n",
    "and indices within a tensor. These can be made interactively in code or an \n",
    "entire set of A and B tensors can be compiled from a structured model\n",
    "description.\n",
    "\n",
    "Below is an example of how to build a distribution from code for a model\n",
    "conisting of a single observation modality \"observation\" consiting of the\n",
    "possible observations {A, B, C, D}. A hidden state \"state\" consisting of the\n",
    "values {A, B, C, D} and controls \"control\" {up, down}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'states' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m B[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     46\u001b[0m policies, C, action, qs, observation \u001b[38;5;241m=\u001b[39m get_task_info()\n\u001b[0;32m---> 48\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mA\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mB\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mC\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m prior, _ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minfer_empirical_prior(action, qs)\n\u001b[1;32m     50\u001b[0m qs \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minfer_states(observation, \u001b[38;5;28;01mNone\u001b[39;00m, prior, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/develop/pymdp/.venv/lib/python3.11/site-packages/equinox/_module.py:548\u001b[0m, in \u001b[0;36m_ModuleMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m initable_cls \u001b[38;5;241m=\u001b[39m _make_initable(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, post_init, wraps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# [Step 2] Instantiate the class as normal.\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ModuleMeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitable_cls\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_abstract(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# [Step 3] Check that all fields are occupied.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/agent.py:139\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, A, B, C, D, E, pA, pB, A_dependencies, B_dependencies, qs, q_pi, H, I, policy_len, control_fac_idx, policies, gamma, alpha, inductive_depth, inductive_threshold, inductive_epsilon, use_utility, use_states_info_gain, use_param_info_gain, use_inductive, onehot_obs, action_selection, sampling_mode, inference_algo, num_iter, learn_A, learn_B, learn_C, learn_D, learn_E)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    101\u001b[0m     A,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     learn_E\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    136\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A_dependencies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m B_dependencies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m         A_dependencies, B_dependencies \u001b[38;5;241m=\u001b[39m \u001b[43mget_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# TODO: infer batch shape in general case, here we assume no batch in Distribution object\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     A \u001b[38;5;241m=\u001b[39m [jnp\u001b[38;5;241m.\u001b[39mexpand_dims(a\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Distribution) \u001b[38;5;28;01melse\u001b[39;00m a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m A]\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/distribution.py:175\u001b[0m, in \u001b[0;36mget_dependencies\u001b[0;34m(transitions, likelihoods)\u001b[0m\n\u001b[1;32m    173\u001b[0m states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m like \u001b[38;5;129;01min\u001b[39;00m likelihoods:\n\u001b[0;32m--> 175\u001b[0m     likelihood_dependencies[\u001b[38;5;28mlist\u001b[39m(like\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions:\n\u001b[1;32m    177\u001b[0m     transition_dependencies[\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    178\u001b[0m         states\u001b[38;5;241m.\u001b[39mindex(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m states\n\u001b[1;32m    179\u001b[0m     ]\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/distribution.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m like \u001b[38;5;129;01min\u001b[39;00m likelihoods:\n\u001b[0;32m--> 175\u001b[0m     likelihood_dependencies[\u001b[38;5;28mlist\u001b[39m(like\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[43mstates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m like\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions:\n\u001b[1;32m    177\u001b[0m     transition_dependencies[\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    178\u001b[0m         states\u001b[38;5;241m.\u001b[39mindex(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m states\n\u001b[1;32m    179\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: 'states' is not in list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from pymdp.jax import Distribution\n",
    "from pymdp.jax.agent import Agent\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "\n",
    "def get_task_info():\n",
    "    policies = jnp.expand_dims(jnp.array([[0, 0, 0, 0], [1, 1, 1, 1]]), -1)\n",
    "    C = jnp.zeros((1, 4))\n",
    "    C = C.at[0, 3].set(1.0)\n",
    "    action = jnp.array([[1]])\n",
    "    qs = [jnp.zeros((1, 1, 4))]\n",
    "    qs[0] = qs[0].at[0, 0, 0].set(1.0)\n",
    "    observation = [jnp.array([[0]])]\n",
    "    return policies, C, action, qs, observation\n",
    "\n",
    "observations = [\"A\", \"B\", \"C\", \"D\"]\n",
    "states = [\"A\", \"B\", \"C\", \"D\"]\n",
    "controls = [\"up\", \"down\"]\n",
    "\n",
    "data = np.zeros((len(observations), len(states)))\n",
    "A = Distribution(data, {\"observations\": observations}, {\"states\": states})\n",
    "\n",
    "A[\"A\", \"A\"] = 1.0 \n",
    "A[\"B\", \"B\"] = 1.0\n",
    "A[\"C\", \"C\"] = 1.0\n",
    "A[\"D\", \"D\"] = 1.0\n",
    "\n",
    "\n",
    "## Transition\n",
    "# Similarily we can use the distributions to build a \n",
    "data = np.zeros((len(states), len(states), len(controls)))\n",
    "B = Distribution(data, {\"states\": states}, {\"states\": states, \"controls\": controls})\n",
    "\n",
    "B[\"B\", \"A\", \"up\"] = 1.0\n",
    "B[\"C\", \"B\", \"up\"] = 1.0\n",
    "B[\"D\", \"C\", \"up\"] = 1.0\n",
    "B[\"D\", \"D\", \"up\"] = 1.0\n",
    "\n",
    "B[\"A\", \"A\", \"down\"] = 1.0\n",
    "B[\"A\", \"B\", \"down\"] = 1.0\n",
    "B[\"B\", \"C\", \"down\"] = 1.0\n",
    "B[\"C\", \"D\", \"down\"] = 1.0\n",
    "\n",
    "policies = jnp.expand_dims(jnp.array([[0, 0, 0, 0], [1, 1, 1, 1]]), -1)\n",
    "\n",
    "C = jnp.zeros((1, 4))\n",
    "C = C.at[0, 0].set(1.0)\n",
    "\n",
    "agent = Agent([A], [B], [C], policies=policies)\n",
    "\n",
    "action = jnp.array([[0]])\n",
    "qs = [jnp.zeros((1, 1, 4))]\n",
    "qs[0] = qs[0].at[0, 0, 0].set(1.0)\n",
    "\n",
    "observation = [jnp.array([[0]])]\n",
    "prior, _ = agent.infer_empirical_prior(action, qs)\n",
    "\n",
    "agent = Agent([A], [B], [C], policies=policies)\n",
    "prior, _ = agent.infer_empirical_prior(action, qs)\n",
    "qs = agent.infer_states(observation, None, prior, None)\n",
    "\n",
    "q_pi, G = agent.infer_policies(qs)\n",
    "action = agent.sample_action(q_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using configs\n",
    "Alternatively you can use a model description to just generate the shape of the\n",
    "A's and the B's in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'s1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m Bs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     31\u001b[0m policies, Cs, action, qs, observation \u001b[38;5;241m=\u001b[39m get_task_info()\n\u001b[0;32m---> 33\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m prior, _ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minfer_empirical_prior(action, qs)\n\u001b[1;32m     35\u001b[0m qs \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minfer_states(observation, \u001b[38;5;28;01mNone\u001b[39;00m, prior, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/develop/pymdp/.venv/lib/python3.11/site-packages/equinox/_module.py:548\u001b[0m, in \u001b[0;36m_ModuleMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m initable_cls \u001b[38;5;241m=\u001b[39m _make_initable(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, post_init, wraps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# [Step 2] Instantiate the class as normal.\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ModuleMeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitable_cls\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_abstract(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# [Step 3] Check that all fields are occupied.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/agent.py:139\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, A, B, C, D, E, pA, pB, A_dependencies, B_dependencies, qs, q_pi, H, I, policy_len, control_fac_idx, policies, gamma, alpha, inductive_depth, inductive_threshold, inductive_epsilon, use_utility, use_states_info_gain, use_param_info_gain, use_inductive, onehot_obs, action_selection, sampling_mode, inference_algo, num_iter, learn_A, learn_B, learn_C, learn_D, learn_E)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    101\u001b[0m     A,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     learn_E\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    136\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A_dependencies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m B_dependencies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m         A_dependencies, B_dependencies \u001b[38;5;241m=\u001b[39m \u001b[43mget_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# TODO: infer batch shape in general case, here we assume no batch in Distribution object\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     A \u001b[38;5;241m=\u001b[39m [jnp\u001b[38;5;241m.\u001b[39mexpand_dims(a\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Distribution) \u001b[38;5;28;01melse\u001b[39;00m a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m A]\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/distribution.py:175\u001b[0m, in \u001b[0;36mget_dependencies\u001b[0;34m(transitions, likelihoods)\u001b[0m\n\u001b[1;32m    173\u001b[0m states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m like \u001b[38;5;129;01min\u001b[39;00m likelihoods:\n\u001b[0;32m--> 175\u001b[0m     likelihood_dependencies[\u001b[38;5;28mlist\u001b[39m(like\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions:\n\u001b[1;32m    177\u001b[0m     transition_dependencies[\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    178\u001b[0m         states\u001b[38;5;241m.\u001b[39mindex(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m states\n\u001b[1;32m    179\u001b[0m     ]\n",
      "File \u001b[0;32m~/develop/pymdp/pymdp/jax/distribution.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m like \u001b[38;5;129;01min\u001b[39;00m likelihoods:\n\u001b[0;32m--> 175\u001b[0m     likelihood_dependencies[\u001b[38;5;28mlist\u001b[39m(like\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[43mstates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m like\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trans \u001b[38;5;129;01min\u001b[39;00m transitions:\n\u001b[1;32m    177\u001b[0m     transition_dependencies[\u001b[38;5;28mlist\u001b[39m(trans\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    178\u001b[0m         states\u001b[38;5;241m.\u001b[39mindex(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m trans\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m states\n\u001b[1;32m    179\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: 's1' is not in list"
     ]
    }
   ],
   "source": [
    "from pymdp.jax import distribution\n",
    "\n",
    "model = {\n",
    "    \"observations\": {\n",
    "        \"o1\": {\"elements\": [\"A\", \"B\", \"C\", \"D\"], \"depends_on\": [\"s1\"]},\n",
    "    },\n",
    "    \"controls\": {\"c1\": {\"elements\": [\"up\", \"down\"]}},\n",
    "    \"states\": {\n",
    "        \"s1\": {\"elements\": [\"A\", \"B\", \"C\", \"D\"], \"depends_on_states\": [\"s1\"], \"depends_on_control\": [\"c1\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "As, Bs = distribution.compile_model(model)\n",
    "print(Bs[0].data.shape)\n",
    "\n",
    "As[0][\"A\", \"A\"] = 1.0\n",
    "As[0][\"B\", \"B\"] = 1.0\n",
    "As[0][\"C\", \"C\"] = 1.0\n",
    "As[0][\"D\", \"D\"] = 1.0\n",
    "\n",
    "Bs[0][\"B\", \"A\", \"up\"] = 1.0\n",
    "Bs[0][\"C\", \"B\", \"up\"] = 1.0\n",
    "Bs[0][\"D\", \"C\", \"up\"] = 1.0\n",
    "Bs[0][\"D\", \"D\", \"up\"] = 1.0\n",
    "\n",
    "Bs[0][\"A\", \"A\", \"down\"] = 1.0\n",
    "Bs[0][\"A\", \"B\", \"down\"] = 1.0\n",
    "Bs[0][\"B\", \"C\", \"down\"] = 1.0\n",
    "Bs[0][\"C\", \"D\", \"down\"] = 1.0\n",
    "\n",
    "policies, Cs, action, qs, observation = get_task_info()\n",
    "\n",
    "agent = Agent(As, Bs, Cs, policies=policies)\n",
    "prior, _ = agent.infer_empirical_prior(action, qs)\n",
    "qs = agent.infer_states(observation, None, prior, None)\n",
    "\n",
    "q_pi, G = agent.infer_policies(qs)\n",
    "action = agent.sample_action(q_pi)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
